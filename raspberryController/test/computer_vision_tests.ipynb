{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "filename = \"../data/minimalist-4k-wallpaper-full-hd.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/carles/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): BasicConv2d(\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux1): None\n",
       "  (aux2): None\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7078,  0.6967,  1.2135,  1.3125,  0.4443,  0.9637,  1.0806, -0.3405,\n",
      "        -0.1046, -0.3838, -0.1112,  0.6114,  0.0998,  0.3613, -0.5853, -0.2264,\n",
      "        -0.2140, -0.7147, -0.7333, -0.4465, -0.4423, -0.6094,  0.8113, -0.3930,\n",
      "        -1.3984, -0.2488, -0.8072, -0.9216, -0.9285, -0.9787, -0.7711, -0.7976,\n",
      "        -0.8260, -0.0283,  0.4088, -1.2062, -0.9969, -1.5558, -1.5875, -0.0104,\n",
      "         0.2832, -1.2856, -0.2541,  0.3487, -0.3434, -0.4405,  0.1212, -1.0697,\n",
      "        -0.5487, -0.8268,  0.6263,  0.1770, -0.7100, -0.8520, -1.0458, -0.4479,\n",
      "        -0.7004, -0.4922, -0.8023, -0.0535, -0.4192, -1.3397, -0.7133, -0.6056,\n",
      "         0.0491, -0.5960, -0.3682, -0.3253, -0.6222, -0.1542, -0.4384, -0.4607,\n",
      "         0.0558, -0.8891, -0.6367, -0.0279,  0.1373,  0.0887, -0.9705, -1.0338,\n",
      "         0.8623,  0.3605, -0.5760,  0.7822, -1.3681, -0.6341, -0.3643, -1.6855,\n",
      "        -0.4352, -1.3453, -0.2808, -0.7258, -0.0583, -2.2511, -1.4156, -0.4711,\n",
      "        -1.2667, -1.5855, -1.6108, -0.7180, -0.4190, -1.1574, -0.2887, -0.1007,\n",
      "        -0.0394, -2.4897,  0.2792,  1.5065,  0.0358, -0.4293, -0.7130, -0.2122,\n",
      "         0.4881, -0.6352, -1.4244, -0.9278, -0.9916,  0.0688,  0.1802, -0.0797,\n",
      "        -1.2978,  0.3986, -0.9943,  0.3174, -0.7309, -1.0373, -1.0576, -1.4813,\n",
      "        -0.9416, -1.4171, -0.0697, -0.9728, -0.9357, -0.4618,  0.2681,  0.5538,\n",
      "        -0.5274, -0.8802, -2.3204,  0.3150, -0.1265, -1.1838, -0.3880, -1.2041,\n",
      "        -0.0951,  3.0136, -0.8390,  0.9413,  2.4249,  0.5910,  1.6802, -1.0974,\n",
      "        -1.1112, -0.5752, -1.1377, -1.2845, -0.9814, -2.2188, -1.5248, -0.3725,\n",
      "        -0.3978,  0.2022, -1.7427,  0.2180,  0.1246, -0.2499, -1.0944, -1.1198,\n",
      "        -0.3946,  1.5033,  1.3619, -1.6892,  1.1184,  0.0590, -0.3025, -1.3212,\n",
      "        -0.3734,  0.6277,  0.1203, -1.7471, -1.3756, -1.2620, -1.4737, -0.7112,\n",
      "        -0.4392,  0.4186, -0.0551, -0.7077, -1.1862, -0.6040,  0.4595,  0.2920,\n",
      "        -0.3556, -1.1507,  0.8926, -0.4877, -1.3254,  0.7284, -0.5760,  0.9310,\n",
      "        -1.1659, -1.3161,  0.0379,  1.1495, -1.0205,  0.3279,  0.1530,  0.8806,\n",
      "         1.0443,  0.8730, -1.0918, -1.4466,  0.2820,  0.4543,  0.5547, -0.5812,\n",
      "        -0.1591, -0.4937, -0.2708,  0.0344,  0.3188, -1.0688,  1.1904,  0.4522,\n",
      "         1.1570,  1.4516,  0.2080,  0.3133, -0.2448, -0.3263, -2.0564,  0.4413,\n",
      "        -0.1534, -0.4909,  0.4283,  1.8370,  0.4870, -1.5266,  1.6075,  1.1032,\n",
      "         1.1637,  1.0994, -1.4051, -0.8624,  0.4252, -1.0940,  2.0839,  2.1465,\n",
      "         1.5117,  1.1185,  1.4257,  0.3944, -0.9551, -1.2827, -1.0653,  1.8190,\n",
      "         0.4605,  1.0970,  0.4678, -0.6931,  0.1485, -1.3535, -0.1520,  0.3473,\n",
      "         1.2086, -0.9769, -0.9811,  0.7016, -2.3222,  0.9915,  0.8883,  0.5022,\n",
      "         0.4381,  0.8430,  0.2121, -0.1620, -1.1838,  0.2833, -0.3800,  0.2296,\n",
      "         0.0651, -0.1726,  0.0722,  0.2843, -0.7354, -0.5920,  0.1022, -0.9068,\n",
      "        -0.7150, -0.7563, -1.0969, -1.2486, -0.3351, -1.4915,  1.5540,  0.5186,\n",
      "         2.7741,  0.5745, -0.6717, -0.2195, -1.6248,  0.2738, -1.2982, -1.6558,\n",
      "        -1.1625, -1.9524, -0.6885, -0.4659, -1.1723,  0.1141, -0.2329, -0.8276,\n",
      "        -0.7307, -0.9640, -0.8503, -0.4939, -1.9272, -1.3909, -0.5955, -1.2336,\n",
      "        -0.8161, -0.5059, -0.1381, -0.2001, -1.2600, -0.5610,  0.0670, -0.1797,\n",
      "         0.8376, -0.0343, -0.0940, -0.3837, -0.8732, -0.8345, -0.1598, -0.6560,\n",
      "         1.0153,  0.4396, -1.4130, -0.3291, -0.1660, -0.5911,  0.0575, -1.4879,\n",
      "        -0.6553,  1.4969,  0.1619,  2.8656,  0.5531,  1.8014,  1.8967, -0.2241,\n",
      "         0.8669, -0.0460,  0.9676,  2.2267,  0.2107,  0.1709, -0.9135, -1.2676,\n",
      "         0.6128, -1.4297, -0.0657, -1.6810, -0.7287, -0.8702, -1.2588, -1.5249,\n",
      "        -1.0093, -1.4226,  0.0303, -0.6341, -0.3775,  0.6836,  0.6539, -1.4638,\n",
      "        -0.6487,  0.0372, -0.2691, -0.4363,  0.4336, -0.8941, -0.1897, -1.4784,\n",
      "        -1.0211, -0.6259, -0.8110, -1.0983, -1.1316, -0.6513, -0.3463,  0.5171,\n",
      "         0.4092, -0.6762,  0.6308, -0.4093, -0.0938, -1.5261, -0.6455,  1.2275,\n",
      "        -0.9418, -0.5425,  0.4744, -1.2729,  0.2646, -0.5966,  0.2531,  1.4899,\n",
      "        -0.9364,  1.5602,  0.5712, -1.2860,  0.5288,  0.1334,  0.2778, -0.2600,\n",
      "        -1.3086,  2.6103, -1.1775, -1.4128, -1.2024,  1.1441, -1.8257, -0.9356,\n",
      "        -0.6220,  2.9351, -0.1497,  0.2590, -0.7319, -2.3592, -1.8672, -1.7729,\n",
      "        -1.4549, -0.1436, -1.5841,  1.8314, -0.3054,  0.8431,  0.1091, -0.9972,\n",
      "         0.1723,  1.7645, -0.2092, -1.0737,  0.4776, -0.6647, -0.2460,  1.1192,\n",
      "        -1.7732,  1.9014,  2.3830,  3.1586, -1.9459, -1.2121, -0.8363, -0.7802,\n",
      "        -0.3418,  0.8139,  0.2807,  1.9768,  2.7568,  0.0534, -0.5938, -0.0651,\n",
      "        -0.5239, -0.2835,  0.4647,  1.3648,  0.4487,  0.8230,  1.2896, -1.0396,\n",
      "         2.6911, -2.1759, -0.5348,  1.8319,  0.4271,  0.3318, -0.1405, -0.4763,\n",
      "         0.6236, -0.7833,  0.1438,  3.0117, -0.8797,  0.5910, -0.1743,  0.0783,\n",
      "         1.8403,  0.4488, -0.5108, -1.1074, -0.1505,  0.1648, -1.5279, -0.8209,\n",
      "        -2.1752,  3.2698,  0.4243, -0.1443,  2.2911,  1.2106, -1.2195,  0.2710,\n",
      "         0.6533,  0.5134,  0.3585,  0.5887,  0.4446, -1.3554, -0.4253, -0.1728,\n",
      "        -1.2453,  0.6939, -0.3636,  0.3435, -0.3580,  0.7821,  1.2905, -0.0562,\n",
      "        -0.9083, -1.3733, -2.6179,  0.0985, -0.9867,  2.9730,  0.4065,  1.0822,\n",
      "        -0.6381, -1.3320,  1.0544, -0.4502, -0.4662, -1.5212, -0.2878, -0.4684,\n",
      "         1.0258,  3.9472, -0.5217, -1.2589, -0.3951, -0.6108, -0.5754, -0.8131,\n",
      "         0.7531, -2.5998,  0.6309,  1.2486, -0.0504,  0.3472,  0.5723, -0.1356,\n",
      "        -0.6228, -0.5765,  0.9425,  0.3510,  1.9153,  0.4072, -0.4288, -0.7148,\n",
      "        -1.6341, -1.8805,  4.0285, -1.1784,  1.8903,  1.2509,  0.5267, -0.8438,\n",
      "         0.4614,  0.1648, -0.4445,  0.7521,  0.8948, -2.2445, -0.7921, -0.3100,\n",
      "        -0.4033, -0.3693,  1.8994, -0.5973,  0.9705,  0.2732,  0.2018, -0.6230,\n",
      "        -1.0127,  0.6585, -1.1751,  0.0894, -1.4184,  0.4277,  0.4298, -1.0061,\n",
      "        -0.6194, -0.4829, -0.5861, -1.7959, -0.5027, -1.0648,  1.8133, -0.1593,\n",
      "         0.2369,  0.2891, -1.6797, -0.6114, -0.3020,  0.1166,  0.6304,  0.7701,\n",
      "        -0.1790,  0.6809,  0.0659,  0.1576, -1.1075,  0.2126, -1.0317, -0.0577,\n",
      "         1.3183,  0.1423, -0.8845,  1.7559,  1.7076, -2.1097,  0.4129, -0.4954,\n",
      "        -1.4727, -0.7974, -0.4439,  0.1065, -0.2528,  0.6703, -0.8949, -0.4207,\n",
      "         0.9565, -0.2695,  0.9213,  0.3744, -0.0293, -0.1939,  0.4253,  0.1735,\n",
      "        -1.1764, -0.6788, -0.2326,  0.1990,  1.7274, -1.2092,  1.1093, -0.4263,\n",
      "        -0.7712,  0.4459,  1.6170,  0.9388, -1.3679, -0.8882,  1.0167, -0.3576,\n",
      "         2.0952,  0.7571, -1.3658,  0.0246,  1.0172, -2.2108,  0.5885,  2.5881,\n",
      "         2.7687, -0.0887, -0.5891, -1.0841, -0.2859,  2.0180, -0.4437,  3.3045,\n",
      "         6.9410,  1.0570, -1.3035,  0.2616, -0.2815,  0.4164, -0.4350,  0.0820,\n",
      "        -1.6669,  1.5632, -0.3777, -0.3436,  0.5166,  0.2072,  0.1073, -0.4543,\n",
      "         2.1062,  0.4497, -0.4410,  1.5513, -0.6487,  1.1040, -1.3202,  0.0168,\n",
      "         0.6172, -0.7709,  0.8853, -1.3423,  0.0779,  1.4200, -1.1662,  0.7447,\n",
      "         0.9983,  0.6341,  1.7412, -0.2714, -1.4691, -0.9374, -0.3739,  1.4464,\n",
      "        -0.1807, -0.5120,  1.0249, -1.7884,  1.4701, -0.1395,  0.9780, -0.3348,\n",
      "        -0.3097, -1.0332, -1.0071, -0.9058, -0.0606,  0.4319, -0.7971,  0.5801,\n",
      "         1.4405, -1.2127, -0.6779, -1.2224, -1.0822,  1.0060, -1.2764,  0.4108,\n",
      "         0.6680, -0.0350, -0.3554,  1.1610,  0.5575,  0.1227, -0.2168, -0.0454,\n",
      "         0.0749,  0.7248,  0.3175, -1.4782, -2.0986, -1.4983, -0.2050, -1.6709,\n",
      "        -2.4730, -1.1325,  0.4695,  0.8665, -0.4198,  2.6907, -0.7452,  0.2909,\n",
      "         1.8205,  0.7121,  1.7906,  0.7730,  0.8455, -0.8755, -0.3888, -0.4180,\n",
      "        -1.6158, -0.1468, -0.6598,  0.2223, -0.1814, -0.3215, -1.4987,  0.4454,\n",
      "         0.2258, -0.1533, -0.9223,  0.4140,  0.3517, -1.7195,  2.3245,  0.5427,\n",
      "        -0.9213, -0.2384, -1.0808, -0.5509, -0.1714,  0.7546, -1.3517, -0.1038,\n",
      "         2.4536,  1.0857,  2.5142,  4.6552,  2.3350,  2.4415, -3.1678,  1.2719,\n",
      "         0.0947, -0.1011,  5.1288,  3.5831, -0.5406, -1.3197, -1.0734,  0.7949,\n",
      "        -0.7699, -0.6491,  0.0971, -0.7053, -0.2358, -0.9488, -0.7487,  0.0702,\n",
      "        -2.9216, -0.7836,  1.5485,  2.1107,  0.1688, -0.0612, -0.3660,  3.4707,\n",
      "        -0.2735,  2.7208,  2.0942,  3.1354, -0.7831,  1.2165, -0.6945,  0.9277,\n",
      "         2.0715, -0.9308,  0.2894, -1.3102,  2.3078,  1.9354, -0.6215,  2.8778,\n",
      "        -1.8540,  0.9326, -0.6224, -0.2035,  0.7293, -0.7797,  0.9265, -0.6305,\n",
      "         0.7440, -0.3698, -1.1906,  2.0623, -1.5015, -0.4450,  3.5319, -0.7999,\n",
      "        -2.2974, -0.3505,  0.1893,  1.1827, -1.2282,  0.0185,  0.6219,  0.7072,\n",
      "        -1.2650, -0.8922, -0.3702,  1.2017, -0.7875, -0.2562, -1.8196, -1.2220,\n",
      "         3.0826, -0.2891, -0.5677, -1.5823,  1.8962, -0.0422, -0.0792,  0.4910,\n",
      "         0.5663, -0.3215,  1.4248, -0.3776,  0.9949,  1.9705,  0.1453, -0.5234,\n",
      "         2.4083, -0.7029, -2.7218, -1.6332,  0.2639, -1.6314, -0.0166,  0.0153,\n",
      "         0.8050,  0.9657,  0.5922,  1.1604, -0.8524, -0.4509,  0.9151,  1.0362,\n",
      "         0.8282,  0.0218, -0.3619,  0.2421,  1.7004, -0.1233, -0.7310, -1.1502,\n",
      "         1.8082,  2.1014,  0.5627,  2.2876,  2.2092,  0.6369, -0.9292, -0.3585,\n",
      "         0.2367,  1.3069,  0.4896, -1.0276, -0.8729, -0.8614, -0.8263,  0.4426,\n",
      "        -1.7052, -0.9142, -0.3544,  0.0427, -0.1102, -0.8723, -1.2940, -1.4595,\n",
      "        -0.0384, -0.7670, -1.3847, -1.3489, -0.7288, -0.3060, -1.2953, -0.8996,\n",
      "         0.0143, -0.2380,  0.7744, -0.1447, -0.1911,  0.5572,  1.6416,  1.2089,\n",
      "        -0.1816, -0.0705,  0.2494, -0.2825, -1.6470, -0.5213,  1.3033, -1.4581,\n",
      "        -1.2466, -0.7023, -1.8103, -1.4141, -1.3891, -1.5907,  0.5201,  0.3564,\n",
      "         2.1615, -0.2077,  9.4720, -0.2934,  4.6592,  1.5250,  6.4979,  5.8400,\n",
      "         2.5807,  1.7391,  3.4148,  8.1785,  6.1574, -3.2261,  0.6139,  1.1089,\n",
      "         1.4203, -0.1250,  0.1067, -0.1537, -0.6958, -0.1395, -0.0658, -0.4389,\n",
      "        -0.6933, -1.3235, -1.5603, -1.9252, -0.3614, -1.7237, -0.1518, -0.2296],\n",
      "       device='cuda:0')\n",
      "tensor([2.3004e-05, 9.3708e-05, 1.5711e-04, 1.7346e-04, 7.2806e-05, 1.2239e-04,\n",
      "        1.3756e-04, 3.3214e-05, 4.2051e-05, 3.1806e-05, 4.1774e-05, 8.6042e-05,\n",
      "        5.1587e-05, 6.7001e-05, 2.6002e-05, 3.7228e-05, 3.7691e-05, 2.2846e-05,\n",
      "        2.2426e-05, 2.9874e-05, 2.9998e-05, 2.5382e-05, 1.0508e-04, 3.1516e-05,\n",
      "        1.1531e-05, 3.6405e-05, 2.0827e-05, 1.8576e-05, 1.8449e-05, 1.7544e-05,\n",
      "        2.1593e-05, 2.1028e-05, 2.0440e-05, 4.5385e-05, 7.0261e-05, 1.3975e-05,\n",
      "        1.7229e-05, 9.8514e-06, 9.5443e-06, 4.6203e-05, 6.1973e-05, 1.2908e-05,\n",
      "        3.6209e-05, 6.6166e-05, 3.3118e-05, 3.0053e-05, 5.2701e-05, 1.6019e-05,\n",
      "        2.6972e-05, 2.0422e-05, 8.7339e-05, 5.5726e-05, 2.2953e-05, 1.9914e-05,\n",
      "        1.6406e-05, 2.9831e-05, 2.3174e-05, 2.8538e-05, 2.0930e-05, 4.4256e-05,\n",
      "        3.0698e-05, 1.2229e-05, 2.2878e-05, 2.5479e-05, 4.9038e-05, 2.5726e-05,\n",
      "        3.2306e-05, 3.3722e-05, 2.5060e-05, 4.0016e-05, 3.0117e-05, 2.9453e-05,\n",
      "        4.9367e-05, 1.9190e-05, 2.4700e-05, 4.5401e-05, 5.3556e-05, 5.1018e-05,\n",
      "        1.7690e-05, 1.6605e-05, 1.1058e-04, 6.6952e-05, 2.6245e-05, 1.0206e-04,\n",
      "        1.1886e-05, 2.4762e-05, 3.2434e-05, 8.6536e-06, 3.0212e-05, 1.2160e-05,\n",
      "        3.5258e-05, 2.2594e-05, 4.4043e-05, 4.9152e-06, 1.1335e-05, 2.9147e-05,\n",
      "        1.3155e-05, 9.5631e-06, 9.3242e-06, 2.2770e-05, 3.0705e-05, 1.4673e-05,\n",
      "        3.4979e-05, 4.2214e-05, 4.4881e-05, 3.8719e-06, 6.1723e-05, 2.1060e-04,\n",
      "        4.8389e-05, 3.0392e-05, 2.2886e-05, 3.7762e-05, 7.6061e-05, 2.4736e-05,\n",
      "        1.1235e-05, 1.8461e-05, 1.7320e-05, 5.0013e-05, 5.5903e-05, 4.3111e-05,\n",
      "        1.2751e-05, 6.9551e-05, 1.7273e-05, 6.4128e-05, 2.2478e-05, 1.6546e-05,\n",
      "        1.6214e-05, 1.0613e-05, 1.8208e-05, 1.1317e-05, 4.3544e-05, 1.7648e-05,\n",
      "        1.8315e-05, 2.9421e-05, 6.1044e-05, 8.1228e-05, 2.7551e-05, 1.9361e-05,\n",
      "        4.5864e-06, 6.3976e-05, 4.1138e-05, 1.4292e-05, 3.1674e-05, 1.4004e-05,\n",
      "        4.2450e-05, 9.5060e-04, 2.0174e-05, 1.1968e-04, 5.2759e-04, 8.4305e-05,\n",
      "        2.5055e-04, 1.5582e-05, 1.5367e-05, 2.6266e-05, 1.4966e-05, 1.2922e-05,\n",
      "        1.7497e-05, 5.0765e-06, 1.0162e-05, 3.2169e-05, 3.1364e-05, 5.7151e-05,\n",
      "        8.1725e-06, 5.8058e-05, 5.2883e-05, 3.6365e-05, 1.5628e-05, 1.5236e-05,\n",
      "        3.1464e-05, 2.0992e-04, 1.8225e-04, 8.6213e-06, 1.4286e-04, 4.9522e-05,\n",
      "        3.4498e-05, 1.2457e-05, 3.2139e-05, 8.7460e-05, 5.2656e-05, 8.1368e-06,\n",
      "        1.1797e-05, 1.3217e-05, 1.0695e-05, 2.2925e-05, 3.0091e-05, 7.0953e-05,\n",
      "        4.4184e-05, 2.3006e-05, 1.4256e-05, 2.5521e-05, 7.3920e-05, 6.2517e-05,\n",
      "        3.2717e-05, 1.4772e-05, 1.1399e-04, 2.8668e-05, 1.2404e-05, 9.6721e-05,\n",
      "        2.6245e-05, 1.1844e-04, 1.4550e-05, 1.2520e-05, 4.8490e-05, 1.4737e-04,\n",
      "        1.6827e-05, 6.4803e-05, 5.4406e-05, 1.1262e-04, 1.3266e-04, 1.1177e-04,\n",
      "        1.5669e-05, 1.0989e-05, 6.1898e-05, 7.3532e-05, 8.1298e-05, 2.6109e-05,\n",
      "        3.9818e-05, 2.8495e-05, 3.5612e-05, 4.8321e-05, 6.4218e-05, 1.6033e-05,\n",
      "        1.5352e-04, 7.3383e-05, 1.4848e-04, 1.9935e-04, 5.7482e-05, 6.3864e-05,\n",
      "        3.6548e-05, 3.3688e-05, 5.9717e-06, 7.2588e-05, 4.0047e-05, 2.8576e-05,\n",
      "        7.1649e-05, 2.9308e-04, 7.5978e-05, 1.0144e-05, 2.3297e-04, 1.4071e-04,\n",
      "        1.4949e-04, 1.4018e-04, 1.1454e-05, 1.9709e-05, 7.1425e-05, 1.5634e-05,\n",
      "        3.7518e-04, 3.9938e-04, 2.1170e-04, 1.4288e-04, 1.9424e-04, 6.9257e-05,\n",
      "        1.7964e-05, 1.2946e-05, 1.6089e-05, 2.8787e-04, 7.3991e-05, 1.3983e-04,\n",
      "        7.4535e-05, 2.3345e-05, 5.4159e-05, 1.2061e-05, 4.0105e-05, 6.6076e-05,\n",
      "        1.5635e-04, 1.7576e-05, 1.7503e-05, 9.4167e-05, 4.5779e-06, 1.2583e-04,\n",
      "        1.1350e-04, 7.7143e-05, 7.2350e-05, 1.0847e-04, 5.7719e-05, 3.9704e-05,\n",
      "        1.4292e-05, 6.1975e-05, 3.1927e-05, 5.8738e-05, 4.9827e-05, 3.9286e-05,\n",
      "        5.0180e-05, 6.2037e-05, 2.2379e-05, 2.5828e-05, 5.1712e-05, 1.8853e-05,\n",
      "        2.2839e-05, 2.1914e-05, 1.5589e-05, 1.3395e-05, 3.3394e-05, 1.0506e-05,\n",
      "        2.2083e-04, 7.8421e-05, 7.4810e-04, 8.2924e-05, 2.3849e-05, 3.7486e-05,\n",
      "        9.1951e-06, 6.1389e-05, 1.2746e-05, 8.9143e-06, 1.4600e-05, 6.6260e-06,\n",
      "        2.3453e-05, 2.9299e-05, 1.4457e-05, 5.2331e-05, 3.6986e-05, 2.0406e-05,\n",
      "        2.2482e-05, 1.7805e-05, 1.9949e-05, 2.8491e-05, 6.7952e-06, 1.1618e-05,\n",
      "        2.5738e-05, 1.3597e-05, 2.0643e-05, 2.8150e-05, 4.0664e-05, 3.8222e-05,\n",
      "        1.3242e-05, 2.6641e-05, 4.9921e-05, 3.9006e-05, 1.0788e-04, 4.5113e-05,\n",
      "        4.2499e-05, 3.1809e-05, 1.9496e-05, 2.0266e-05, 3.9793e-05, 2.4227e-05,\n",
      "        1.2886e-04, 7.2464e-05, 1.1364e-05, 3.3594e-05, 3.9545e-05, 2.5851e-05,\n",
      "        4.9449e-05, 1.0544e-05, 2.4243e-05, 2.0858e-04, 5.4890e-05, 8.1982e-04,\n",
      "        8.1171e-05, 2.8282e-04, 3.1113e-04, 3.7313e-05, 1.1109e-04, 4.4589e-05,\n",
      "        1.2286e-04, 4.3274e-04, 5.7636e-05, 5.5390e-05, 1.8727e-05, 1.3143e-05,\n",
      "        8.6164e-05, 1.1176e-05, 4.3719e-05, 8.6923e-06, 2.2528e-05, 1.9555e-05,\n",
      "        1.3259e-05, 1.0161e-05, 1.7016e-05, 1.1256e-05, 4.8124e-05, 2.4763e-05,\n",
      "        3.2008e-05, 9.2489e-05, 8.9782e-05, 1.0801e-05, 2.4404e-05, 4.8458e-05,\n",
      "        3.5671e-05, 3.0181e-05, 7.2027e-05, 1.9095e-05, 3.8620e-05, 1.0645e-05,\n",
      "        1.6816e-05, 2.4966e-05, 2.0749e-05, 1.5567e-05, 1.5057e-05, 2.4341e-05,\n",
      "        3.3022e-05, 7.8298e-05, 7.0293e-05, 2.3741e-05, 8.7730e-05, 3.1006e-05,\n",
      "        4.2505e-05, 1.0149e-05, 2.4481e-05, 1.5932e-04, 1.8205e-05, 2.7140e-05,\n",
      "        7.5024e-05, 1.3073e-05, 6.0826e-05, 2.5709e-05, 6.0135e-05, 2.0713e-04,\n",
      "        1.8303e-05, 2.2221e-04, 8.2649e-05, 1.2903e-05, 7.9226e-05, 5.3349e-05,\n",
      "        6.1635e-05, 3.5999e-05, 1.2614e-05, 6.3509e-04, 1.4381e-05, 1.1366e-05,\n",
      "        1.4028e-05, 1.4658e-04, 7.5214e-06, 1.8318e-05, 2.5064e-05, 8.7883e-04,\n",
      "        4.0196e-05, 6.0490e-05, 2.2457e-05, 4.4117e-06, 7.2155e-06, 7.9290e-06,\n",
      "        1.0898e-05, 4.0442e-05, 9.5770e-06, 2.9145e-04, 3.4401e-05, 1.0848e-04,\n",
      "        5.2068e-05, 1.7224e-05, 5.5464e-05, 2.7260e-04, 3.7872e-05, 1.5955e-05,\n",
      "        7.5271e-05, 2.4016e-05, 3.6504e-05, 1.4297e-04, 7.9272e-06, 3.1256e-04,\n",
      "        5.0595e-04, 1.0989e-03, 6.6699e-06, 1.3892e-05, 2.0229e-05, 2.1397e-05,\n",
      "        3.3169e-05, 1.0536e-04, 6.1813e-05, 3.3707e-04, 7.3526e-04, 4.9245e-05,\n",
      "        2.5781e-05, 4.3743e-05, 2.7649e-05, 3.5160e-05, 7.4307e-05, 1.8277e-04,\n",
      "        7.3121e-05, 1.0632e-04, 1.6954e-04, 1.6508e-05, 6.8854e-04, 5.2991e-06,\n",
      "        2.7348e-05, 2.9159e-04, 7.1559e-05, 6.5058e-05, 4.0569e-05, 2.8997e-05,\n",
      "        8.7103e-05, 2.1331e-05, 5.3907e-05, 9.4878e-04, 1.9370e-05, 8.4303e-05,\n",
      "        3.9219e-05, 5.0489e-05, 2.9405e-04, 7.3133e-05, 2.8013e-05, 1.5426e-05,\n",
      "        4.0165e-05, 5.5053e-05, 1.0130e-05, 2.0544e-05, 5.3031e-06, 1.2281e-03,\n",
      "        7.1358e-05, 4.0414e-05, 4.6154e-04, 1.5665e-04, 1.3790e-05, 6.1219e-05,\n",
      "        8.9723e-05, 7.8011e-05, 6.6819e-05, 8.4113e-05, 7.2823e-05, 1.2038e-05,\n",
      "        3.0514e-05, 3.9278e-05, 1.3439e-05, 9.3442e-05, 3.2454e-05, 6.5820e-05,\n",
      "        3.2638e-05, 1.0206e-04, 1.6969e-04, 4.4137e-05, 1.8824e-05, 1.1824e-05,\n",
      "        3.4061e-06, 5.1521e-05, 1.7405e-05, 9.1275e-04, 7.0102e-05, 1.3778e-04,\n",
      "        2.4664e-05, 1.2323e-05, 1.3400e-04, 2.9764e-05, 2.9289e-05, 1.0199e-05,\n",
      "        3.5012e-05, 2.9227e-05, 1.3023e-04, 2.4178e-03, 2.7708e-05, 1.3258e-05,\n",
      "        3.1449e-05, 2.5347e-05, 2.6260e-05, 2.0705e-05, 9.9143e-05, 3.4684e-06,\n",
      "        8.7740e-05, 1.6273e-04, 4.4391e-05, 6.6063e-05, 8.2742e-05, 4.0765e-05,\n",
      "        2.5046e-05, 2.6233e-05, 1.1982e-04, 6.6319e-05, 3.1694e-04, 7.0153e-05,\n",
      "        3.0405e-05, 2.2843e-05, 9.1103e-06, 7.1206e-06, 2.6226e-03, 1.4369e-05,\n",
      "        3.0912e-04, 1.6310e-04, 7.9052e-05, 2.0078e-05, 7.4055e-05, 5.5053e-05,\n",
      "        2.9932e-05, 9.9045e-05, 1.1424e-04, 4.9478e-06, 2.1143e-05, 3.4241e-05,\n",
      "        3.1192e-05, 3.2271e-05, 3.1195e-04, 2.5692e-05, 1.2322e-04, 6.1351e-05,\n",
      "        5.7125e-05, 2.5040e-05, 1.6959e-05, 9.0198e-05, 1.4416e-05, 5.1051e-05,\n",
      "        1.1303e-05, 7.1605e-05, 7.1756e-05, 1.7070e-05, 2.5129e-05, 2.8807e-05,\n",
      "        2.5982e-05, 7.7490e-06, 2.8240e-05, 1.6097e-05, 2.8623e-04, 3.9812e-05,\n",
      "        5.9168e-05, 6.2339e-05, 8.7036e-06, 2.5332e-05, 3.4518e-05, 5.2461e-05,\n",
      "        8.7698e-05, 1.0084e-04, 3.9036e-05, 9.2233e-05, 4.9867e-05, 5.4655e-05,\n",
      "        1.5425e-05, 5.7745e-05, 1.6640e-05, 4.4071e-05, 1.7447e-04, 5.3825e-05,\n",
      "        1.9278e-05, 2.7026e-04, 2.5751e-04, 5.6617e-06, 7.0556e-05, 2.8447e-05,\n",
      "        1.0705e-05, 2.1032e-05, 2.9951e-05, 5.1934e-05, 3.6256e-05, 9.1265e-05,\n",
      "        1.9079e-05, 3.0653e-05, 1.2150e-04, 3.5657e-05, 1.1730e-04, 6.7890e-05,\n",
      "        4.5338e-05, 3.8456e-05, 7.1432e-05, 5.5531e-05, 1.4397e-05, 2.3680e-05,\n",
      "        3.6998e-05, 5.6969e-05, 2.6265e-04, 1.3933e-05, 1.4157e-04, 3.0482e-05,\n",
      "        2.1590e-05, 7.2922e-05, 2.3521e-04, 1.1938e-04, 1.1888e-05, 1.9207e-05,\n",
      "        1.2904e-04, 3.2649e-05, 3.7941e-04, 9.9541e-05, 1.1914e-05, 4.7850e-05,\n",
      "        1.2911e-04, 5.1177e-06, 8.4093e-05, 6.2112e-04, 7.4408e-04, 4.2725e-05,\n",
      "        2.5903e-05, 1.5790e-05, 3.5078e-05, 3.5123e-04, 2.9956e-05, 1.2715e-03,\n",
      "        4.8263e-02, 1.3434e-04, 1.2679e-05, 6.0648e-05, 3.5231e-05, 7.0797e-05,\n",
      "        3.0217e-05, 5.0677e-05, 8.8161e-06, 2.2288e-04, 3.2001e-05, 3.3112e-05,\n",
      "        7.8264e-05, 5.7432e-05, 5.1976e-05, 2.9641e-05, 3.8361e-04, 7.3195e-05,\n",
      "        3.0037e-05, 2.2025e-04, 2.4405e-05, 1.4082e-04, 1.2469e-05, 4.7479e-05,\n",
      "        8.6546e-05, 2.1597e-05, 1.1316e-04, 1.2197e-05, 5.0471e-05, 1.9315e-04,\n",
      "        1.4545e-05, 9.8313e-05, 1.2669e-04, 8.8024e-05, 2.6630e-04, 3.5591e-05,\n",
      "        1.0744e-05, 1.8284e-05, 3.2123e-05, 1.9831e-04, 3.8967e-05, 2.7980e-05,\n",
      "        1.3010e-04, 7.8069e-06, 2.0306e-04, 4.0607e-05, 1.2414e-04, 3.3402e-05,\n",
      "        3.4253e-05, 1.6615e-05, 1.7054e-05, 1.8871e-05, 4.3940e-05, 7.1908e-05,\n",
      "        2.1038e-05, 8.3396e-05, 1.9715e-04, 1.3884e-05, 2.3703e-05, 1.3750e-05,\n",
      "        1.5819e-05, 1.2767e-04, 1.3027e-05, 7.0405e-05, 9.1058e-05, 4.5083e-05,\n",
      "        3.2722e-05, 1.4907e-04, 8.1531e-05, 5.2782e-05, 3.7585e-05, 4.4616e-05,\n",
      "        5.0318e-05, 9.6376e-05, 6.4134e-05, 1.0647e-05, 5.7249e-06, 1.0435e-05,\n",
      "        3.8032e-05, 8.7808e-06, 3.9370e-06, 1.5044e-05, 7.4659e-05, 1.1105e-04,\n",
      "        3.0682e-05, 6.8826e-04, 2.2160e-05, 6.2448e-05, 2.8829e-04, 9.5158e-05,\n",
      "        2.7980e-04, 1.0113e-04, 1.0874e-04, 1.9452e-05, 3.1648e-05, 3.0738e-05,\n",
      "        9.2785e-06, 4.0313e-05, 2.4135e-05, 5.8311e-05, 3.8943e-05, 3.3849e-05,\n",
      "        1.0431e-05, 7.2883e-05, 5.8512e-05, 4.0051e-05, 1.8563e-05, 7.0628e-05,\n",
      "        6.6367e-05, 8.3641e-06, 4.7719e-04, 8.0331e-05, 1.8581e-05, 3.6783e-05,\n",
      "        1.5841e-05, 2.6911e-05, 3.9331e-05, 9.9291e-05, 1.2082e-05, 4.2082e-05,\n",
      "        5.4295e-04, 1.3827e-04, 5.7686e-04, 4.9081e-03, 4.8223e-04, 5.3643e-04,\n",
      "        1.9653e-06, 1.6656e-04, 5.1323e-05, 4.2197e-05, 7.8817e-03, 1.6800e-03,\n",
      "        2.7189e-05, 1.2475e-05, 1.5959e-05, 1.0337e-04, 2.1618e-05, 2.4394e-05,\n",
      "        5.1449e-05, 2.3062e-05, 3.6879e-05, 1.8078e-05, 2.2081e-05, 5.0083e-05,\n",
      "        2.5140e-06, 2.1325e-05, 2.1964e-04, 3.8533e-04, 5.5269e-05, 4.3915e-05,\n",
      "        3.2376e-05, 1.5015e-03, 3.5516e-05, 7.0930e-04, 3.7904e-04, 1.0737e-03,\n",
      "        2.1335e-05, 1.5758e-04, 2.3311e-05, 1.1805e-04, 3.7053e-04, 1.8405e-05,\n",
      "        6.2355e-05, 1.2594e-05, 4.6928e-04, 3.2340e-04, 2.5077e-05, 8.2983e-04,\n",
      "        7.3115e-06, 1.1863e-04, 2.5055e-05, 3.8089e-05, 9.6807e-05, 2.1407e-05,\n",
      "        1.1792e-04, 2.4852e-05, 9.8249e-05, 3.2253e-05, 1.4194e-05, 3.6713e-04,\n",
      "        1.0402e-05, 2.9919e-05, 1.5962e-03, 2.0979e-05, 4.6927e-06, 3.2882e-05,\n",
      "        5.6414e-05, 1.5235e-04, 1.3670e-05, 4.7560e-05, 8.6949e-05, 9.4695e-05,\n",
      "        1.3177e-05, 1.9130e-05, 3.2242e-05, 1.5527e-04, 2.1241e-05, 3.6135e-05,\n",
      "        7.5671e-06, 1.3756e-05, 1.0185e-03, 3.4965e-05, 2.6464e-05, 9.5944e-06,\n",
      "        3.1096e-04, 4.4756e-05, 4.3132e-05, 7.6286e-05, 8.2247e-05, 3.3852e-05,\n",
      "        1.9408e-04, 3.2004e-05, 1.2627e-04, 3.3494e-04, 5.3990e-05, 2.7663e-05,\n",
      "        5.1894e-04, 2.3116e-05, 3.0700e-06, 9.1176e-06, 6.0787e-05, 9.1343e-06,\n",
      "        4.5919e-05, 4.7404e-05, 1.0442e-04, 1.2262e-04, 8.4407e-05, 1.4898e-04,\n",
      "        1.9908e-05, 2.9742e-05, 1.1657e-04, 1.3159e-04, 1.0688e-04, 4.7717e-05,\n",
      "        3.2509e-05, 5.9473e-05, 2.5566e-04, 4.1272e-05, 2.2476e-05, 1.4780e-05,\n",
      "        2.8476e-04, 3.8177e-04, 8.1958e-05, 4.5991e-04, 4.2523e-04, 8.8266e-05,\n",
      "        1.8436e-05, 3.2621e-05, 5.9157e-05, 1.7250e-04, 7.6173e-05, 1.6707e-05,\n",
      "        1.9502e-05, 1.9728e-05, 2.0432e-05, 7.2677e-05, 8.4849e-06, 1.8713e-05,\n",
      "        3.2755e-05, 4.8726e-05, 4.1815e-05, 1.9515e-05, 1.2800e-05, 1.0847e-05,\n",
      "        4.4927e-05, 2.1681e-05, 1.1691e-05, 1.2116e-05, 2.2526e-05, 3.4380e-05,\n",
      "        1.2784e-05, 1.8990e-05, 4.7358e-05, 3.6797e-05, 1.0128e-04, 4.0396e-05,\n",
      "        3.8566e-05, 8.1504e-05, 2.4107e-04, 1.5639e-04, 3.8934e-05, 4.3507e-05,\n",
      "        5.9909e-05, 3.5197e-05, 8.9934e-06, 2.7720e-05, 1.7188e-04, 1.0863e-05,\n",
      "        1.3421e-05, 2.3130e-05, 7.6381e-06, 1.1351e-05, 1.1639e-05, 9.5139e-06,\n",
      "        7.8532e-05, 6.6676e-05, 4.0542e-04, 3.7931e-05, 6.0648e-01, 3.4816e-05,\n",
      "        4.9279e-03, 2.1454e-04, 3.0990e-02, 1.6051e-02, 6.1656e-04, 2.6575e-04,\n",
      "        1.4197e-03, 1.6637e-01, 2.2046e-02, 1.8541e-06, 8.6263e-05, 1.4151e-04,\n",
      "        1.9321e-04, 4.1201e-05, 5.1943e-05, 4.0035e-05, 2.3281e-05, 4.0608e-05,\n",
      "        4.3715e-05, 3.0101e-05, 2.3339e-05, 1.2428e-05, 9.8077e-06, 6.8090e-06,\n",
      "        3.2525e-05, 8.3294e-06, 4.0112e-05, 3.7110e-05], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "    \n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-17 11:39:18--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10472 (10K) [text/plain]\n",
      "Saving to: ‘imagenet_classes.txt.1’\n",
      "\n",
      "imagenet_classes.tx 100%[===================>]  10,23K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-05-17 11:39:19 (50,0 MB/s) - ‘imagenet_classes.txt.1’ saved [10472/10472]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alp 0.606482207775116\n",
      "valley 0.16636939346790314\n",
      "mountain tent 0.048262834548950195\n",
      "geyser 0.03098953701555729\n",
      "volcano 0.022045640274882317\n"
     ]
    }
   ],
   "source": [
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
